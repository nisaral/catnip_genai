{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai\n",
    "\n",
    "\n",
    "openai.api_key = \"\"#openai api key \n",
    "\n",
    "\n",
    "orders_df = pd.read_csv('/Users/krishilparikh/Desktop/SynCom-FinanceMitra/KB/KBorders.csv')\n",
    "shipments_df = pd.read_csv('/Users/krishilparikh/Desktop/SynCom-FinanceMitra/KB/KBshipments.csv')\n",
    "products_df = pd.read_csv('/Users/krishilparikh/Desktop/SynCom-FinanceMitra/KB/KBproducts.csv')\n",
    "\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "def embed_data(df, columns):\n",
    "    texts = df[columns].fillna(\"\").astype(str).agg(\" \".join, axis=1).tolist()\n",
    "    embeddings = model.encode(texts, convert_to_tensor=True).cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "orders_embeddings = embed_data(orders_df, [\"Order ID\", \"Customer Name\", \"Product Description\", \"Order Status\"])\n",
    "shipments_embeddings = embed_data(shipments_df, [\"Tracking ID\", \"Shipping Address\", \"Shipment Status\", \"Product Description\"])\n",
    "products_embeddings = embed_data(products_df, [\"Product ID\", \"Product Name\", \"Product Description\", \"Price\", \"Product Category\"])\n",
    "\n",
    "all_embeddings = {\n",
    "    \"orders\": orders_embeddings,\n",
    "    \"shipments\": shipments_embeddings,\n",
    "    \"products\": products_embeddings\n",
    "}\n",
    "\n",
    "\n",
    "dataframes = {\n",
    "    \"orders\": orders_df,\n",
    "    \"shipments\": shipments_df,\n",
    "    \"products\": products_df\n",
    "}\n",
    "\n",
    "\n",
    "conversation_history = []\n",
    "\n",
    "# Function to search for relevant data\n",
    "def search_relevant_data(user_query):\n",
    "    \n",
    "    matches = []\n",
    "    for category, df in dataframes.items():\n",
    "        for col in df.columns:\n",
    "            match = df[df[col].astype(str).str.contains(user_query, case=False, na=False)]\n",
    "            if not match.empty:\n",
    "                matches.append((category, match, col))\n",
    "\n",
    "    if matches:\n",
    "        # Return the first match found\n",
    "        best_match = matches[0]\n",
    "        return best_match[1].iloc[0], best_match[0]\n",
    "\n",
    "    # If no exact match, use embeddings for similarity search\n",
    "    query_embedding = model.encode([user_query], convert_to_tensor=True).cpu().numpy()\n",
    "    similarities = {category: cosine_similarity(query_embedding, embeddings).flatten() for category, embeddings in all_embeddings.items()}\n",
    "    \n",
    "    # Identify the best matching category and row\n",
    "    best_category = max(similarities, key=lambda cat: np.max(similarities[cat]))\n",
    "    best_index = np.argmax(similarities[best_category])\n",
    "    return dataframes[best_category].iloc[best_index], best_category\n",
    "\n",
    "# Function to generate a response using OpenAI API\n",
    "def generate_response(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=prompt,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# Function to build OpenAI messages from conversation history\n",
    "def build_prompt(user_query, relevant_data, category):\n",
    "  \n",
    "    context_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Here is the relevant data from the {category} category:\\n{relevant_data.to_dict()}\"\n",
    "    }\n",
    "    conversation_history.append(context_message)\n",
    "\n",
    "    \n",
    "    user_message = {\"role\": \"user\", \"content\": user_query}\n",
    "    conversation_history.append(user_message)\n",
    "\n",
    "    return conversation_history\n",
    "\n",
    "# Main function to process the user query\n",
    "def process_query(user_input):\n",
    "   \n",
    "    relevant_data, category = search_relevant_data(user_input)\n",
    "\n",
    "    # Display the relevant data\n",
    "    print(f\"\\nRelevant Data from {category.capitalize()}:\\n\")\n",
    "    print(relevant_data.to_frame().T.to_string(index=False)) \n",
    "    \n",
    "    prompt = build_prompt(user_input, relevant_data, category)\n",
    "\n",
    "    # Generate a response\n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Bot: How can I assist you today?\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break\n",
    "        response = process_query(user_input)\n",
    "        print(f\"\\nBot: {response}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
