{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"b9f0c1e033f7f4447e906abad9033ba03d46370fe52f38df008a2d6ba759c442"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7155963,"sourceType":"datasetVersion","datasetId":4132570},{"sourceId":6799776,"sourceType":"datasetVersion","datasetId":3912165}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Model building and Routing","metadata":{}},{"cell_type":"code","source":"# Work in progress","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:29:06.269215Z","iopub.execute_input":"2025-01-05T18:29:06.269616Z","iopub.status.idle":"2025-01-05T18:29:06.275446Z","shell.execute_reply.started":"2025-01-05T18:29:06.269584Z","shell.execute_reply":"2025-01-05T18:29:06.273866Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Downloading required routing data","metadata":{}},{"cell_type":"code","source":"#!pip install copernicus_marine_client","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:29:06.821573Z","iopub.execute_input":"2025-01-05T18:29:06.821967Z","iopub.status.idle":"2025-01-05T18:29:06.826795Z","shell.execute_reply.started":"2025-01-05T18:29:06.821918Z","shell.execute_reply":"2025-01-05T18:29:06.825541Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#!pip install netcdf4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:29:06.887053Z","iopub.execute_input":"2025-01-05T18:29:06.887438Z","iopub.status.idle":"2025-01-05T18:29:06.892394Z","shell.execute_reply.started":"2025-01-05T18:29:06.887407Z","shell.execute_reply":"2025-01-05T18:29:06.891079Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#! pip install scipy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:29:06.913674Z","iopub.execute_input":"2025-01-05T18:29:06.914046Z","iopub.status.idle":"2025-01-05T18:29:06.919023Z","shell.execute_reply.started":"2025-01-05T18:29:06.914018Z","shell.execute_reply":"2025-01-05T18:29:06.917725Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#!pip install store","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:29:06.950989Z","iopub.execute_input":"2025-01-05T18:29:06.951388Z","iopub.status.idle":"2025-01-05T18:29:06.956140Z","shell.execute_reply.started":"2025-01-05T18:29:06.951358Z","shell.execute_reply":"2025-01-05T18:29:06.955047Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import copernicus_marine_client as copernicusmarine\n\ncopernicusmarine.subset(\n  dataset_id=\"cmems_mod_glo_phy_anfc_0.083deg_PT1H-m\",\n  variables=[\"so\", \"thetao\"],\n  minimum_longitude=-180,\n  maximum_longitude=179.91668701171875,\n  minimum_latitude=-80,\n  maximum_latitude=90,\n  start_datetime=\"2023-06-01T00:00:00\",\n  end_datetime=\"2023-06-01T23:59:00\",\n  minimum_depth=0.49402499198913574,\n  maximum_depth=0.49402499198913574,\n)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T18:29:07.028647Z","iopub.execute_input":"2025-01-05T18:29:07.029111Z","iopub.status.idle":"2025-01-05T18:29:07.053445Z","shell.execute_reply.started":"2025-01-05T18:29:07.029077Z","shell.execute_reply":"2025-01-05T18:29:07.052069Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopernicus_marine_client\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcopernicusmarine\u001b[39;00m\n\u001b[1;32m      3\u001b[0m copernicusmarine\u001b[38;5;241m.\u001b[39msubset(\n\u001b[1;32m      4\u001b[0m   dataset_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcmems_mod_glo_phy_anfc_0.083deg_PT1H-m\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m   variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mso\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthetao\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m   maximum_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.49402499198913574\u001b[39m,\n\u001b[1;32m     14\u001b[0m )\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'copernicus_marine_client'"],"ename":"ModuleNotFoundError","evalue":"No module named 'copernicus_marine_client'","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import requests\nimport zipfile\nimport os\nimport pandas as pd\nimport ftplib\nimport os\nimport xarray as xr\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom joblib import dump, load\nfrom pathlib import Path","metadata":{"execution":{"iopub.status.busy":"2025-01-05T18:29:07.159017Z","iopub.execute_input":"2025-01-05T18:29:07.159994Z","iopub.status.idle":"2025-01-05T18:29:09.026689Z","shell.execute_reply.started":"2025-01-05T18:29:07.159912Z","shell.execute_reply":"2025-01-05T18:29:09.025477Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Get data for the model","metadata":{}},{"cell_type":"code","source":"# load the merged and preprocessed data\ndata = pd.read_csv('/kaggle/input/preprocessed-marine-route-ais-data-jan12023/preprocessed_data.csv')","metadata":{"execution":{"iopub.status.busy":"2025-01-05T18:29:09.028635Z","iopub.execute_input":"2025-01-05T18:29:09.029222Z","iopub.status.idle":"2025-01-05T18:29:10.268071Z","shell.execute_reply.started":"2025-01-05T18:29:09.029186Z","shell.execute_reply":"2025-01-05T18:29:10.266755Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2025-01-05T18:29:10.269555Z","iopub.execute_input":"2025-01-05T18:29:10.269914Z","iopub.status.idle":"2025-01-05T18:29:10.313442Z","shell.execute_reply.started":"2025-01-05T18:29:10.269883Z","shell.execute_reply":"2025-01-05T18:29:10.311396Z"},"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"        Unnamed: 0      EstimatedTime       LAT       LON  Heading  SOG_norm  \\\n0                0  23-01-01 00:00:00  28.28428 -79.63630      2.0  0.849515   \n1                1  23-01-01 00:00:00  25.88697 -80.05251    182.0  0.092233   \n2                3  23-01-01 00:00:00  24.02975 -81.70948     89.0  0.446602   \n3                4  23-01-01 00:00:00  23.87015 -83.77240    104.0  0.432039   \n4                5  23-01-01 00:00:00  32.66685 -78.33462    248.0  0.237864   \n...            ...                ...       ...       ...      ...       ...   \n305781      373403  23-04-01 23:01:00  25.51555 -79.53770    183.0  0.262136   \n305782      373404  23-04-01 23:01:00  25.71019 -83.15791      1.0  0.150485   \n305783      373405  23-04-01 23:01:00  29.39362 -80.81100    178.0  0.208738   \n305784      373406  23-04-01 23:01:00  25.50736 -79.53787    183.0  0.262136   \n305785      373407  23-04-01 23:01:00  24.23551 -81.77254     81.0  0.436893   \n\n        COG_norm  GrossTonnage_norm  VHM0_norm  VMDR_norm  VTPK_norm  \\\n0       0.002222           0.490541   0.470990   0.369275   0.928495   \n1       0.512222           0.014649   0.136519   0.486196   0.270011   \n2       0.259167           0.245103   0.245734   0.340603   0.304162   \n3       0.287500           0.564122   0.204778   0.455503   0.394877   \n4       0.691667           0.358949   0.686007   0.625033   0.929562   \n...          ...                ...        ...        ...        ...   \n305781  0.502500           0.567973   0.133106   0.716368   0.382070   \n305782  0.009444           0.210196   0.177474   0.764988   0.287086   \n305783  0.499167           0.065629   0.290102   0.362679   0.940235   \n305784  0.503333           0.567973   0.133106   0.716368   0.382070   \n305785  0.220833           0.249121   0.204778   0.401777   0.316969   \n\n        Temperature_norm  Salinity_norm  \n0               0.922872       0.977493  \n1               0.844779       0.977550  \n2               0.962990       0.971043  \n3               0.958419       0.975808  \n4               0.869339       0.980886  \n...                  ...            ...  \n305781          0.931087       0.974290  \n305782          0.849249       0.978398  \n305783          0.689712       0.975270  \n305784          0.931087       0.974290  \n305785          0.929055       0.973751  \n\n[305786 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>EstimatedTime</th>\n      <th>LAT</th>\n      <th>LON</th>\n      <th>Heading</th>\n      <th>SOG_norm</th>\n      <th>COG_norm</th>\n      <th>GrossTonnage_norm</th>\n      <th>VHM0_norm</th>\n      <th>VMDR_norm</th>\n      <th>VTPK_norm</th>\n      <th>Temperature_norm</th>\n      <th>Salinity_norm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>23-01-01 00:00:00</td>\n      <td>28.28428</td>\n      <td>-79.63630</td>\n      <td>2.0</td>\n      <td>0.849515</td>\n      <td>0.002222</td>\n      <td>0.490541</td>\n      <td>0.470990</td>\n      <td>0.369275</td>\n      <td>0.928495</td>\n      <td>0.922872</td>\n      <td>0.977493</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>23-01-01 00:00:00</td>\n      <td>25.88697</td>\n      <td>-80.05251</td>\n      <td>182.0</td>\n      <td>0.092233</td>\n      <td>0.512222</td>\n      <td>0.014649</td>\n      <td>0.136519</td>\n      <td>0.486196</td>\n      <td>0.270011</td>\n      <td>0.844779</td>\n      <td>0.977550</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>23-01-01 00:00:00</td>\n      <td>24.02975</td>\n      <td>-81.70948</td>\n      <td>89.0</td>\n      <td>0.446602</td>\n      <td>0.259167</td>\n      <td>0.245103</td>\n      <td>0.245734</td>\n      <td>0.340603</td>\n      <td>0.304162</td>\n      <td>0.962990</td>\n      <td>0.971043</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>23-01-01 00:00:00</td>\n      <td>23.87015</td>\n      <td>-83.77240</td>\n      <td>104.0</td>\n      <td>0.432039</td>\n      <td>0.287500</td>\n      <td>0.564122</td>\n      <td>0.204778</td>\n      <td>0.455503</td>\n      <td>0.394877</td>\n      <td>0.958419</td>\n      <td>0.975808</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>23-01-01 00:00:00</td>\n      <td>32.66685</td>\n      <td>-78.33462</td>\n      <td>248.0</td>\n      <td>0.237864</td>\n      <td>0.691667</td>\n      <td>0.358949</td>\n      <td>0.686007</td>\n      <td>0.625033</td>\n      <td>0.929562</td>\n      <td>0.869339</td>\n      <td>0.980886</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>305781</th>\n      <td>373403</td>\n      <td>23-04-01 23:01:00</td>\n      <td>25.51555</td>\n      <td>-79.53770</td>\n      <td>183.0</td>\n      <td>0.262136</td>\n      <td>0.502500</td>\n      <td>0.567973</td>\n      <td>0.133106</td>\n      <td>0.716368</td>\n      <td>0.382070</td>\n      <td>0.931087</td>\n      <td>0.974290</td>\n    </tr>\n    <tr>\n      <th>305782</th>\n      <td>373404</td>\n      <td>23-04-01 23:01:00</td>\n      <td>25.71019</td>\n      <td>-83.15791</td>\n      <td>1.0</td>\n      <td>0.150485</td>\n      <td>0.009444</td>\n      <td>0.210196</td>\n      <td>0.177474</td>\n      <td>0.764988</td>\n      <td>0.287086</td>\n      <td>0.849249</td>\n      <td>0.978398</td>\n    </tr>\n    <tr>\n      <th>305783</th>\n      <td>373405</td>\n      <td>23-04-01 23:01:00</td>\n      <td>29.39362</td>\n      <td>-80.81100</td>\n      <td>178.0</td>\n      <td>0.208738</td>\n      <td>0.499167</td>\n      <td>0.065629</td>\n      <td>0.290102</td>\n      <td>0.362679</td>\n      <td>0.940235</td>\n      <td>0.689712</td>\n      <td>0.975270</td>\n    </tr>\n    <tr>\n      <th>305784</th>\n      <td>373406</td>\n      <td>23-04-01 23:01:00</td>\n      <td>25.50736</td>\n      <td>-79.53787</td>\n      <td>183.0</td>\n      <td>0.262136</td>\n      <td>0.503333</td>\n      <td>0.567973</td>\n      <td>0.133106</td>\n      <td>0.716368</td>\n      <td>0.382070</td>\n      <td>0.931087</td>\n      <td>0.974290</td>\n    </tr>\n    <tr>\n      <th>305785</th>\n      <td>373407</td>\n      <td>23-04-01 23:01:00</td>\n      <td>24.23551</td>\n      <td>-81.77254</td>\n      <td>81.0</td>\n      <td>0.436893</td>\n      <td>0.220833</td>\n      <td>0.249121</td>\n      <td>0.204778</td>\n      <td>0.401777</td>\n      <td>0.316969</td>\n      <td>0.929055</td>\n      <td>0.973751</td>\n    </tr>\n  </tbody>\n</table>\n<p>305786 rows × 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## Simple model: Linear regression","metadata":{}},{"cell_type":"code","source":"# Target variable\ny = data.SOG_norm\n\n# Predictors\nfeatures = ['VHM0_norm','VMDR_norm', 'VTPK_norm', 'Temperature_norm','Salinity_norm'] \nX = data[features]\n\n# Split data to train and validation\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2025-01-05T18:29:10.316760Z","iopub.execute_input":"2025-01-05T18:29:10.317332Z","iopub.status.idle":"2025-01-05T18:29:10.376898Z","shell.execute_reply.started":"2025-01-05T18:29:10.317292Z","shell.execute_reply":"2025-01-05T18:29:10.375829Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"* The target variable y is derived from the 'SOG_norm' column in the 'data' DataFrame, representing the normalized speed over ground.\n\n* The predictor variables are selected and stored in the 'features' list, including 'VHM0_norm', 'VMDR_norm', 'VTPK_norm', 'Temperature_norm', and 'Salinity_norm'.\n\n* The data is split into training and validation sets using the train_test_split function from scikit-learn, with a specified random seed for reproducibility (random_state=0).\n\n* The resulting sets are:\n\n    * train_X and train_y: Features and target variable for the training set.\n    * val_X and val_y: Features and target variable for the validation set.\n\nThis preparation sets the stage for training a regression model using the training set and assessing its performance on the validation set. The chosen features are expected to help predict the normalized speed over ground based on the provided data.","metadata":{}},{"cell_type":"code","source":"# Create linear regression object\nregr = linear_model.LinearRegression()\n\n# Train the model using the training sets\nregr.fit(train_X, train_y)\n\n# Make predictions using the testing set\npred_y = regr.predict(val_X)\n\n# The coefficients\nprint('Coefficients: \\n', regr.coef_)\n\n# The mean squared error\nprint('Mean squared error: %.2f'\n      % mean_squared_error(val_y, pred_y))\n      \nprint('R^2: %.2f'\n      % r2_score(val_y, pred_y))","metadata":{"execution":{"iopub.status.busy":"2025-01-05T18:29:10.378347Z","iopub.execute_input":"2025-01-05T18:29:10.378663Z","iopub.status.idle":"2025-01-05T18:29:10.495028Z","shell.execute_reply.started":"2025-01-05T18:29:10.378633Z","shell.execute_reply":"2025-01-05T18:29:10.493325Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Coefficients: \n [ 0.13028443 -0.06199205 -0.07919482  0.22646212 -0.20788068]\nMean squared error: 0.03\nR^2: 0.09\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"**Linear Regression Object Creation:**\nA linear regression object (regr) is created using scikit-learn's LinearRegression class.\n\n**Training the Model:**\nThe model is trained using the fit method with the training sets (train_X and train_y).\n\n**Making Predictions:**\nPredictions are made on the testing set (val_X) using the trained model, and the results are stored in pred_y.\n\n**Printing Coefficients:**\nThe coefficients of the linear regression model are printed.\n\n**Calculating Mean Squared Error:**\nThe mean squared error between the true values (val_y) and the predicted values (pred_y) is calculated and printed.\n\n**Calculating R-squared (R^2) Score:**\nThe R-squared score, which measures the proportion of the variance in the dependent variable that is predictable from the independent variables, is calculated and printed.","metadata":{}},{"cell_type":"markdown","source":"## Advanced model: Random forest","metadata":{}},{"cell_type":"code","source":"my_file = Path('rf_model.joblib')\n\nif my_file.is_file():\n    forest_model = load('rf_model.joblib') \n\nelse:\n    forest_model = RandomForestRegressor(random_state = 1)\n    forest_model.fit(train_X, train_y)\n    pred_y = forest_model.predict(val_X)\n\n    print('Mean squared error: %.2f'\n          % mean_squared_error(val_y, pred_y))\n\n    print('R^2: %.2f'\n          % r2_score(val_y, pred_y))\n\n    dump(forest_model, 'rf_model.joblib') \n\n# Add variable importance\nfeature_importance_values = forest_model.feature_importances_\nfeature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})","metadata":{"execution":{"iopub.status.busy":"2025-01-05T18:29:10.497038Z","iopub.execute_input":"2025-01-05T18:29:10.498427Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"R^2 of Random forest: 0.89","metadata":{}},{"cell_type":"markdown","source":"checking if a pre-trained Random Forest Regressor model file ('rf_model.joblib') exists. If it does, the model is loaded; otherwise, a new model is trained, evaluated on a validation set, and saved to the file. Feature importances are calculated and stored in a DataFrame. The code includes loading, training, evaluation, and saving steps for the model, as well as feature importance calculation.","metadata":{}},{"cell_type":"code","source":"def plot_feature_importances(df):\n    \n    \"\"\"Plot importances returned by a model. This can work with any measure of\n    feature importance provided that higher importance is better. \n    \n    Args:\n        df (dataframe): feature importances. Must have the features in a column\n        called `features` and the importances in a column called 'importance'\n    Returns:\n        shows a plot of the 15 most importance features\n        \n        df (dataframe): feature importances sorted by importance (highest to lowest) \n        with a column for normalized importance\n        \"\"\"\n    \n    # Sort features according to importance\n    df = df.sort_values('importance', ascending = False).reset_index()\n    \n    # Normalize the feature importances to add up to one\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n\n    # Make a horizontal bar chart of feature importances\n    plt.figure(figsize = (10, 6))\n    ax = plt.subplot()\n    \n    # Need to reverse the index to plot most important on top\n    ax.barh(list(reversed(list(df.index[:15]))), \n            df['importance_normalized'].head(15), \n            align = 'center', edgecolor = 'k')\n    \n    # Set the yticks and labels\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    \n    # Plot labeling\n    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n    plt.show()\n    \n    return df\n\n# Show the feature importances for the default features\nfeature_importances_sorted = plot_feature_importances(feature_importances)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Sorting and Normalizing Feature Importances:**\nThe function takes a DataFrame (df) containing features and their corresponding importances.\nIt sorts the DataFrame based on the importance values in descending order, ensuring that the most important features come first.\nThe importances are normalized, ensuring that they collectively add up to one. Normalization helps in comparing the relative importance of each feature.\n\n**Generating a Horizontal Bar Chart:**\nThe function utilizes Matplotlib to create a horizontal bar chart with a specified figure size (10x6).\nThe top 15 features are selected for visualization to focus on the most significant contributors.\n\n**Plotting the Normalized Feature Importances:**\nThe horizontal bars represent the normalized importance of each feature.\nThe y-axis displays the feature names, and the x-axis represents the normalized importance values.\nThe bar chart provides a clear visual indication of which features have the greatest impact on the model.\n\n**Displaying the Plot:**\nThe plot is shown, allowing for immediate visual interpretation of feature importances.\n\n**Returning Sorted Feature Importances:**\nThe function returns the input DataFrame (df) after sorting and normalization. This sorted DataFrame can be useful for further analysis or inspection.\n\nIn summary, the plot_feature_importances function simplifies the process of understanding and interpreting the importance of features in a model by providing an informative bar chart. This visualization is particularly helpful for identifying the most influential features and gaining insights into their impact on the model's predictions.","metadata":{}},{"cell_type":"markdown","source":"# Routing","metadata":{}},{"cell_type":"markdown","source":"## Get forecast data for the routing","metadata":{}},{"cell_type":"markdown","source":"- 2023-06-01\n","metadata":{}},{"cell_type":"code","source":"wav_all = xr.open_mfdataset('/kaggle/input/routing-ocean-wav-202301-june/cmems_mod_glo_wav_anfc_0.083deg_PT3H-i_1698308781382.nc')\nwav_all","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"phy_all = xr.open_mfdataset('/kaggle/working/cmems_mod_glo_phy_anfc_0.083deg_PT1H-m_so-thetao_180.00W-179.92E_80.00S-90.00N_0.49m_2023-06-01-2023-06-01.nc')\nphy_all","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Area of interest","metadata":{}},{"cell_type":"markdown","source":"Calculate the optimal shipping route between Washington and Havana considering wave and weather forecasts.\n\nWashington: 38.8951° N 77.0364° W\n\nHavana: 23.1136° N 82.3666° W","metadata":{}},{"cell_type":"code","source":"# Get array index to the value that is closest to a given value\ndef get_closest(array, value):\n    return np.abs(array - value).argmin()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set bounding box for the allowed routing corridor\nbbox = ((-65, 20),(-100, 43))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get indices of the bbox\nlon_min = get_closest(wav_all.longitude.data, bbox[0][0])\nlat_min = get_closest(wav_all.latitude.data, bbox[0][1])\nlon_max = get_closest(wav_all.longitude.data, bbox[1][0])\nlat_max = get_closest(wav_all.latitude.data, bbox[1][1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Simple solution: Calculate optimal route with weights for one day","metadata":{}},{"cell_type":"markdown","source":"- 2021-06-01","metadata":{}},{"cell_type":"code","source":"# Define first common time (12:00:00)\ntime_slice_wav = 0\ntime_slice_phy = 0\n# Extract array from dataset to define the cost in the routing algorithm \n# Wave height\nwave_height = wav_all.VHM0.isel(time=time_slice_wav, longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max))\n\n# Wave direction\nwave_dir = wav_all.VMDR.isel(time=time_slice_wav, longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max))\n\n# Wave period\nwave_per = wav_all.VTPK.isel(time=time_slice_wav, longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max))\n\n# Temperature\ntemp = phy_all.thetao.isel(time=time_slice_phy, longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max), depth = 0)\n\n# Salinity\nsal = phy_all.so.isel(time=time_slice_phy, longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max), depth = 0)\n\n","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wave_height","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Start and end point of the route","metadata":{}},{"cell_type":"code","source":"lat_Wash = 38.8951\nlon_Wash = -77.0364\n\nlat_Hav = 23.1136\nlon_Hav = -82.3666","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# compute great_circle distance @see: https://medium.com/@petehouston/calculate-distance-of-two-locations-on-earth-using-python-1501b1944d97\n\nfrom math import radians, degrees, sin, cos, asin, acos, sqrt\ndef great_circle(lon1, lat1, lon2, lat2):\n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n    return 6371 * (\n        acos(sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(lon1 - lon2))\n    )\n\nprint(\"Distance between Washington and Havana in km: \",great_circle(lon_Wash,lat_Wash, lon_Hav, lat_Hav))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ndef get_closest(array, value):\n    if len(array) == 0:\n        raise ValueError(\"The array is empty.\")\n    \n    return np.abs(array - value).argmin()\n\n# Example usage:\ntry:\n    start_lon = get_closest(wave_height.longitude.data, lon_Wash)\n    start_lat = get_closest(wave_height.latitude.data, lat_Wash)\n    end_lon = get_closest(wave_height.longitude.data, lon_Hav)\n    end_lat = get_closest(wave_height.latitude.data, lat_Hav)\n    \n    # Continue with the rest of your code\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_lon = get_closest(wave_height.longitude.data, lon_Wash)\nstart_lat = get_closest(wave_height.latitude.data, lat_Wash)\nend_lon = get_closest(wave_height.longitude.data,lon_Hav)\nend_lat = get_closest(wave_height.latitude.data,lat_Hav)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start = (start_lat, start_lon)\nend = (end_lat, end_lon)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot wave height as an example variable\nplt.figure(figsize=(10,17))\n\n# Costs\nplt.imshow(wave_height.data, aspect='auto')\n\nplt.title(\"Wave height (CMEMS)\")\nplt.colorbar()\nplt.axis(\"off\")\nplt.gca().invert_yaxis()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Mask land areas\nland_mask = wave_height.data.copy() \nland_mask[np.isnan(land_mask)] = 1\nland_mask[land_mask != 1] = 0","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot optimal route\nplt.figure(figsize=(10,17))\n\nplt.imshow(land_mask, aspect='auto', cmap = 'cividis')\nplt.text(start[1],start[0], 'Lisbon', color = 'black', fontfamily = 'serif', fontsize = 'small')\nplt.text(end[1]-10,end[0]+30, 'Rio de Janeiro', color = 'black', fontfamily = 'serif', fontsize = 'small')\nplt.text(100, 600, 'Antlantic Ocean', color = 'white', fontfamily = 'serif', fontsize = 'x-large')\nplt.text(1, 200, 'South America', color = 'black', fontfamily = 'serif', fontsize = 'x-large')\nplt.text(380, 550, 'Africa', color = 'black', fontfamily = 'serif', fontsize = 'x-large')\nplt.title('Land mask', fontsize = 16, pad = 18)\nplt.axis(\"off\")\nplt.gca().invert_yaxis()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Get variable costs","metadata":{}},{"cell_type":"code","source":"# Assign data directly as costs\nwh_costs = wave_height.data\nwd_costs = wave_dir.data\nwp_costs = wave_per.data\ntemp_costs = temp.data\nsal_costs = sal.data\nthi_costs = thi.data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def stand_and_norm (x): \n    \"\"\"Returns the standardized and normalized array.\"\"\"\n    # Standardization\n    x_stand = (x - np.nanmean(x)) / np.nanstd(x)\n\n    # Normalization\n    x_norm = (x_stand - np.nanmin(x_stand)) / (np.nanmax(x_stand) - np.nanmin(x_stand))\n\n    # Check for na values and assign them with maximum values\n    if(np.any(np.isnan(x_norm))):\n        x_norm[np.isnan(x_norm)] = 1 \n\n    return x_norm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wh_costs = stand_and_norm(wh_costs)\nwd_costs = stand_and_norm(wd_costs)\nwp_costs = stand_and_norm(wp_costs)\ntemp_costs = stand_and_norm(temp_costs)\nsal_costs = stand_and_norm(sal_costs)\nthi_costs = stand_and_norm(thi_costs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Calulate costs based on linear regression model","metadata":{}},{"cell_type":"code","source":"# Get regression coefficients\nrc = regr.coef_\n\n# Weight are taken from linear regression model\nspeed = rc[0]*wh_costs + rc[1]*wd_costs + rc[2]*wp_costs + rc[3]*temp_costs + rc[4]*sal_costs + rc[5]*thi_costs\n\n# invert costs, because costs imitate speed \ninverted_speed = -1*speed + np.abs(np.max(speed))","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wh_costs[land_mask == 1] = 1\ninverted_speed[land_mask == 1] = 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot optimal route\nplt.figure(figsize=(10,17))\n\n# Costs\nplt.imshow(inverted_speed, aspect='auto')\nplt.colorbar()\nplt.gca().invert_yaxis()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inverted_speed = inverted_speed.compute()","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from skimage.graph import route_through_array\n\n# Calculate optimal route based on the minimum cost path\n\n# Optional parameters:\n# - fully_connected \n#     - False -> only axial moves are allowed\n#     - True  -> diagonal moves are allowed\n# - geometric \n#     - False -> minimum cost path\n#     - True  -> distance-weighted minimum cost path\n\nwh_indices, weight = route_through_array(wh_costs, start, end, fully_connected=True, geometric=True)\nwh_indices = np.stack(wh_indices, axis=-1)\n\nwd_indices, weight = route_through_array(wd_costs, start, end, fully_connected=True, geometric=True)\nwd_indices = np.stack(wd_indices, axis=-1)\n\nwp_indices, weight = route_through_array(wp_costs, start, end, fully_connected=True, geometric=True)\nwp_indices = np.stack(wp_indices, axis=-1)\n\ntemp_indices, weight = route_through_array(temp_costs, start, end, fully_connected=True, geometric=True)\ntemp_indices = np.stack(temp_indices, axis=-1)\n\nsal_indices, weight = route_through_array(sal_costs, start, end, fully_connected=True, geometric=True)\nsal_indices = np.stack(sal_indices, axis=-1)\n\nthi_indices, weight = route_through_array(thi_costs, start, end, fully_connected=True, geometric=True)\nthi_indices = np.stack(thi_indices, axis=-1)\n\nmerged_indices, weight_lr = route_through_array(inverted_speed, start, end, fully_connected=True, geometric=True)\nmerged_indices = np.stack(merged_indices, axis=-1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot optimal route\nplt.figure(figsize=(10,17))\n\n# Costs\nplt.imshow(inverted_speed, aspect='auto')\n\n# Routes\nplt.plot(wh_indices[1], wh_indices[0], 'red', label = 'Wave height')\nplt.plot(wd_indices[1], wd_indices[0], 'grey', label = 'Wave direction')\nplt.plot(wp_indices[1], wp_indices[0], 'orange', label = 'Wave period')\nplt.plot(temp_indices[1], temp_indices[0], 'gold', label = 'Temperature')\nplt.plot(sal_indices[1], sal_indices[0], 'cyan', label = 'Salinity')\nplt.plot(thi_indices[1], thi_indices[0], 'crimson', label = 'Thickness')\nplt.plot(merged_indices[1], merged_indices[0], 'black', label = 'All variables')\n\n# Start/end points\nplt.plot(start_lon, start_lat, 'k^', markersize = 15, color = 'white')\nplt.text(start_lon - 70, start_lat - 10, 'Lisbon', fontsize = 20, color = 'white')\nplt.plot(end_lon, end_lat, 'k*', markersize = 15)\nplt.text(end_lon + 30, end_lat - 3, 'Rio de Janeiro', fontsize = 20)\nplt.title('Linear regression: Optimal routes', fontsize = 18, pad = 12)\nplt.colorbar(label='Inverted speed over ground')\nplt.legend(loc = \"lower right\", prop={'size': 18})\nplt.gca().invert_yaxis()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Calulate costs based on random forest model","metadata":{}},{"cell_type":"code","source":"# Reshape 2d array to dataframes to apply the random forest\nwave_height_1d = pd.DataFrame(data = wh_costs.compute().ravel())\nwave_dir_1d = pd.DataFrame(data = wd_costs.compute().ravel())\nwave_per_1d = pd.DataFrame(data = wp_costs.compute().ravel())\ntemp_1d = pd.DataFrame(data = temp_costs.compute().ravel())\nsal_1d = pd.DataFrame(data = sal_costs.compute().ravel())\nthi_1d = pd.DataFrame(data = thi_costs.compute().ravel())\n\nconcat_costs = pd.concat([wave_height_1d, wave_dir_1d, wave_per_1d, temp_1d, sal_1d, thi_1d], axis = 1)\nconcat_costs.columns = ['Wave height', 'Wave direction', 'Wave period', 'Temperature', 'Salinity', 'Thickness']\n\nfor_pred = forest_model.predict(concat_costs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Invert costs, because costs imitate speed \ninverted_speed_forest = -1 * for_pred + np.abs(np.max(for_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reshape speed costs to get back the map\nwave_height_np = wh_costs.compute()\n\nmap_shape = wave_height_np.shape\n\nrf_speed = np.reshape(inverted_speed_forest, map_shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assign non-water areas high values\nrf_speed[land_mask ==1] = 1 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute route\n# Distance weighted minimum cost path\nrf_indices, weight_simple_day_one = route_through_array(rf_speed, start, end, fully_connected=True, geometric=True)\nrf_indices = np.stack(rf_indices, axis=-1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Presentation plot simple solution\n# Plot optimal route\nplt.figure(figsize=(10,17))\n\n# Costs\nplt.imshow(rf_speed, aspect='auto')\n\nplt.plot(rf_indices[1],rf_indices[0], 'red', label = 'One day', lw = 5)\n\n# Start/end points\nplt.plot(start_lon, start_lat, 'k^', markersize = 15, color = 'white')\nplt.text(start_lon - 70, start_lat - 10, 'Lisbon', fontsize = 20, color = 'white')\nplt.plot(end_lon, end_lat, 'k*', markersize = 15)\nplt.text(end_lon + 30, end_lat - 3, 'Rio de Janeiro', fontsize = 20)\n#plt.title('Simple solution (one day)', fontsize = 18, pad = 12)\nplt.legend(loc = 'lower right', prop={'size': 22})\n# plt.colorbar(label='Inverted speed over ground')\nplt.axis('off')\nplt.gca().invert_yaxis()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Advanced solution: Calculate optimal route based on *multiple* variables and *multiple* days","metadata":{}},{"cell_type":"code","source":"# Show times for WAV\ntime = phy_all.sel(time=~phy_all.get_index('time').duplicated()).time\n\nrows = []\n\nfor step in range(time.size):\n    \n    time_df_phy = str(time.values[step])\n    rows.append([step, time_df_phy])\n\ntime_df_phy = pd.DataFrame(rows, columns = ['Step', 'Time'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show times for PHY\ntime = wav_all.sel(time=~wav_all.get_index('time').duplicated()).time\n\nrows = []\n\nfor step in range(time.size):\n    \n    time_df_wav = str(time.values[step])\n    rows.append([step, time_df_wav])\n\ntime_df_wav = pd.DataFrame(rows, columns = ['Step', 'Time'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.106849Z","iopub.status.idle":"2025-01-05T18:27:13.107505Z","shell.execute_reply.started":"2025-01-05T18:27:13.107210Z","shell.execute_reply":"2025-01-05T18:27:13.107240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the times that exist in both datasets (12:00:00 for the three days)\ncommon_time = np.intersect1d(time_df_wav['Time'], time_df_phy['Time'])\n\n# Create arrays with the corresponding steps - For waves forecast: [3, 11, 19, 27] & For physics forecast: [0, 1, 2, 3]\ntime_wav = []\ntime_phy = []\n\nfor t in range(common_time.size):\n    time_wav.append(int(time_df_wav['Step'].loc[time_df_wav['Time'] == common_time[t]]))\n    time_phy.append(int(time_df_phy['Step'].loc[time_df_phy['Time'] == common_time[t]]))\n\n# Create time slices (start, end, step)\nstep_wav = time_wav[1] - time_wav[0]\ntime_slice_wav = slice(min(time_wav), max(time_wav) + 1, step_wav)\nstep_phy = time_phy[1] - time_phy[0]\ntime_slice_phy = slice(min(time_phy), max(time_phy) + 1, step_phy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.116712Z","iopub.status.idle":"2025-01-05T18:27:13.117365Z","shell.execute_reply.started":"2025-01-05T18:27:13.117071Z","shell.execute_reply":"2025-01-05T18:27:13.117103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract array from dataset to define the cost in the routing algorithm with a new time_slice\n# Wave height\nwave_height_3day = wav_all.VHM0.isel(time=time_slice_wav, longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max))\n\n# Wave direction\nwave_dir_3day = wav_all.VMDR.isel(time=time_slice_wav, longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max))\n\n# Wave period\nwave_per_3day = wav_all.VTPK.isel(time=time_slice_wav, longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max))\n\n# Temperature\ntemp_3day = phy_all.thetao.isel(time=time_slice_phy, longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max), depth = 0)\n\n# Salinity\nsal_3day = phy_all.so.isel(time=time_slice_phy, longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max), depth = 0)\n\n# Thickness\nthi_3day = phy_all.mlotst.isel(time=time_slice_phy, longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.118757Z","iopub.status.idle":"2025-01-05T18:27:13.119321Z","shell.execute_reply.started":"2025-01-05T18:27:13.119054Z","shell.execute_reply":"2025-01-05T18:27:13.119080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wh_costs_3d = wave_height_3day.data.compute()\nwd_costs_3d = wave_dir_3day.data.compute()\nwp_costs_3d = wave_per_3day.data.compute()\nte_costs_3d = temp_3day.data.compute()\nsa_costs_3d = sal_3day.data.compute()\nth_costs_3d = thi_3day.data.compute()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.121058Z","iopub.status.idle":"2025-01-05T18:27:13.121571Z","shell.execute_reply.started":"2025-01-05T18:27:13.121314Z","shell.execute_reply":"2025-01-05T18:27:13.121338Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# standardize each time slice (day)\nfor i in range (np.shape(wave_height_3day)[0]):\n    wh_costs_3d[i] = stand_and_norm(wh_costs_3d[i])\n    wd_costs_3d[i] = stand_and_norm(wd_costs_3d[i])\n    wp_costs_3d[i] = stand_and_norm(wp_costs_3d[i])\n    te_costs_3d[i] = stand_and_norm(te_costs_3d[i])\n    sa_costs_3d[i] = stand_and_norm(sa_costs_3d[i])\n    th_costs_3d[i] = stand_and_norm(th_costs_3d[i])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.122945Z","iopub.status.idle":"2025-01-05T18:27:13.123458Z","shell.execute_reply.started":"2025-01-05T18:27:13.123206Z","shell.execute_reply":"2025-01-05T18:27:13.123231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reshape 2d array to dataframes to apply the random forest\nwave_height_1d = pd.DataFrame(data = wh_costs_3d.flatten())\nwave_dir_1d = pd.DataFrame(data = wd_costs_3d.flatten())\nwave_per_1d = pd.DataFrame(data = wp_costs_3d.flatten())\ntemp_1d = pd.DataFrame(data = te_costs_3d.flatten())\nsal_1d = pd.DataFrame(data = sa_costs_3d.flatten())\nthi_1d = pd.DataFrame(data = th_costs_3d.flatten())\n\nconcat_costs = pd.concat([wave_height_1d, wave_dir_1d, wave_per_1d, temp_1d, sal_1d, thi_1d], axis = 1)\nconcat_costs.columns = ['Wave height', 'Wave direction', 'Wave period', 'Temperature', 'Salinity', 'Thickness']\n\n# Predict speed using random forest model\ncosts = forest_model.predict(concat_costs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.125025Z","iopub.status.idle":"2025-01-05T18:27:13.125665Z","shell.execute_reply.started":"2025-01-05T18:27:13.125356Z","shell.execute_reply":"2025-01-05T18:27:13.125390Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reshape speed costs to get back the map\ncosts = np.reshape(costs,wh_costs_3d.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.127476Z","iopub.status.idle":"2025-01-05T18:27:13.128039Z","shell.execute_reply.started":"2025-01-05T18:27:13.127741Z","shell.execute_reply":"2025-01-05T18:27:13.127767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sum costs for all timesteps\ncosts_all_times_mean = (costs[0] + costs[1] + costs[2])/3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.129895Z","iopub.status.idle":"2025-01-05T18:27:13.130467Z","shell.execute_reply.started":"2025-01-05T18:27:13.130195Z","shell.execute_reply":"2025-01-05T18:27:13.130220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assign non-water areas high values\ncosts_all_times_mean[land_mask ==1] = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.131904Z","iopub.status.idle":"2025-01-05T18:27:13.132305Z","shell.execute_reply.started":"2025-01-05T18:27:13.132137Z","shell.execute_reply":"2025-01-05T18:27:13.132155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get data for a specific timestep\ncosts_day_1 = costs[0]\ncosts_day_2 = costs[1]\ncosts_day_3 = costs[2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.133779Z","iopub.status.idle":"2025-01-05T18:27:13.134316Z","shell.execute_reply.started":"2025-01-05T18:27:13.134057Z","shell.execute_reply":"2025-01-05T18:27:13.134082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assign max values for land areas\ncosts_day_1[land_mask == 1] = 1\ncosts_day_2[land_mask == 1] = 1\ncosts_day_3[land_mask == 1] = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.135738Z","iopub.status.idle":"2025-01-05T18:27:13.136273Z","shell.execute_reply.started":"2025-01-05T18:27:13.136020Z","shell.execute_reply":"2025-01-05T18:27:13.136045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Distance weighted minimum cost path (dw-mcp)\n\n# Calculate optimal route for all days\nmerged_indices_all_times, weight_all_times = route_through_array(costs_all_times_mean, start, end, fully_connected=True, geometric=True)\nmerged_indices_all_times = np.stack(merged_indices_all_times, axis=-1)\n\n# Calculate optimal route for day one\nmerged_indices_day_one, weight_day_one = route_through_array(costs_day_1, start, end, fully_connected=True, geometric=True)\nmerged_indices_day_one = np.stack(merged_indices_day_one, axis=-1)\n\n# Calculate optimal route for day two\nmerged_indices_day_two, weight = route_through_array(costs_day_2, start, end, fully_connected=True, geometric=True)\nmerged_indices_day_two = np.stack(merged_indices_day_two, axis=-1)\n\n# Calculate optimal route for day three\nmerged_indices_day_three, weight = route_through_array(costs_day_3, start, end, fully_connected=True, geometric=True)\nmerged_indices_day_three = np.stack(merged_indices_day_three, axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.137554Z","iopub.status.idle":"2025-01-05T18:27:13.138074Z","shell.execute_reply.started":"2025-01-05T18:27:13.137793Z","shell.execute_reply":"2025-01-05T18:27:13.137816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot optimal route\nplt.figure(figsize=(10,17))\n\n# Costs\nplt.imshow(costs_all_times_mean, aspect='auto')\n\n# Routes\nplt.plot(merged_indices_day_one[1], merged_indices_day_one[0], 'yellow', label = 'Day 1')\nplt.plot(merged_indices_day_two[1], merged_indices_day_two[0], 'black', label = 'Day 2')\nplt.plot(merged_indices_day_three[1], merged_indices_day_three[0], 'magenta', label = 'Day 3')\nplt.plot(merged_indices_all_times[1], merged_indices_all_times[0], 'red', label = \"All days\", lw = 5)\n\n# Start/end points\nplt.plot(start_lon, start_lat, 'k^', markersize = 15, color = 'white')\nplt.text(start_lon - 70, start_lat - 10, 'Lisbon', fontsize = 20, color = 'white')\nplt.plot(end_lon, end_lat, 'k*', markersize = 15)\nplt.text(end_lon + 30, end_lat - 3, 'Rio de Janeiro', fontsize = 20)\nplt.title('Optimal routes from Lisbon to Rio de Janeiro based on RF', fontsize = 18, pad = 12)\n# plt.colorbar(label = 'Inverted speed over ground all days')\nplt.legend(loc = 'lower right', prop={'size': 22})\nplt.gca().invert_yaxis()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.139387Z","iopub.status.idle":"2025-01-05T18:27:13.139868Z","shell.execute_reply.started":"2025-01-05T18:27:13.139623Z","shell.execute_reply":"2025-01-05T18:27:13.139647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Presentation plot intermediate solution distance-weighted minimum cost path\n# Plot optimal route\nplt.figure(figsize=(10,17))\n\n# Costs\nplt.imshow(costs_all_times_mean, aspect='auto')\n\n# Routes\nplt.plot(rf_indices[1], rf_indices[0], 'black', label = 'One day')\nplt.plot(merged_indices_all_times[1], merged_indices_all_times[0], 'red', label = \"Three days (mean)\", lw = 5)\n\n# Start/end points\nplt.plot(start_lon, start_lat, 'k^', markersize = 15, color = 'white')\nplt.text(start_lon - 70, start_lat - 10, 'Lisbon', fontsize = 20, color = 'white')\nplt.plot(end_lon, end_lat, 'k*', markersize = 15)\nplt.text(end_lon + 30, end_lat - 3, 'Rio de Janeiro', fontsize = 20)\n#plt.title('Intermediate solution (mean)', fontsize = 18, pad = 12)\n#plt.colorbar(label = 'Inverted speed over ground all days')\nplt.legend(loc = 'lower right', prop={'size': 22})\nplt.axis('off')\nplt.gca().invert_yaxis()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.141220Z","iopub.status.idle":"2025-01-05T18:27:13.141701Z","shell.execute_reply.started":"2025-01-05T18:27:13.141457Z","shell.execute_reply":"2025-01-05T18:27:13.141481Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Advanced solution (costs separated)","metadata":{}},{"cell_type":"code","source":"# Find indices that can be reached within one day\n# @see: https://stackoverflow.com/questions/52920499/find-all-points-within-distance-1-of-specific-point-in-2d-numpy-matrix\n# Set up matrix\nday_all_mask = np.zeros(map_shape)\n\n# Convert to python scalars\nr = start[0]\nc = start[1]\n# Get boundaries of array\nm, n = day_all_mask.shape\n\n# Set this value to a distance that the ship can reach within one day\ndist_per_day = 300\n\n# Loop over possible locations\nfor i in range(0-r,m): \n    for j in range(0-c,n): \n        # Check if location is within boundary\n        if (0 <= r + i < m and 0 <= c + j < n):\n            if np.linalg.norm([r+i,c+j] - np.array(start))<dist_per_day:\n                day_all_mask[r+i,c+j] = 1\n            elif (np.linalg.norm([r+i,c+j] - np.array(start))>=dist_per_day and \n                  np.linalg.norm([r+i,c+j] - np.array(start))<2*dist_per_day):\n                day_all_mask[r+i,c+j] = 2\n            else:\n                day_all_mask[r+i,c+j] = 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.143238Z","iopub.status.idle":"2025-01-05T18:27:13.143715Z","shell.execute_reply.started":"2025-01-05T18:27:13.143471Z","shell.execute_reply":"2025-01-05T18:27:13.143496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot cost splitting\nplt.figure(figsize=(10,17))\n\nplt.text(300, 700, 'Day 1', color = 'black', fontfamily = 'serif', fontsize = 26)\nplt.text(200, 400, 'Day 2', color = 'black', fontfamily = 'serif', fontsize = 26)\nplt.text(100, 100, 'Day 3', color = 'white', fontfamily = 'serif', fontsize = 26)\n\n# Costs\nplt.imshow(day_all_mask, aspect = 'auto',cmap=\"Blues\")\nplt.imshow(land_mask, aspect='auto', cmap = 'RdBu', alpha=0.3)\n# plt.title('Costs separation', fontsize = 16, pad = 18)\nplt.gca().invert_yaxis()\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.145433Z","iopub.status.idle":"2025-01-05T18:27:13.145770Z","shell.execute_reply.started":"2025-01-05T18:27:13.145610Z","shell.execute_reply":"2025-01-05T18:27:13.145626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"costs_ecd = np.zeros(map_shape) # ecd = euclidean distance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.147101Z","iopub.status.idle":"2025-01-05T18:27:13.147450Z","shell.execute_reply.started":"2025-01-05T18:27:13.147288Z","shell.execute_reply":"2025-01-05T18:27:13.147305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"costs_ecd[day_all_mask == 1] = costs[0][day_all_mask == 1]\ncosts_ecd[day_all_mask == 2] = costs[1][day_all_mask == 2]\ncosts_ecd[day_all_mask == 3] = costs[2][day_all_mask == 3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.148795Z","iopub.status.idle":"2025-01-05T18:27:13.149172Z","shell.execute_reply.started":"2025-01-05T18:27:13.148998Z","shell.execute_reply":"2025-01-05T18:27:13.149017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate optimal route for all days distance-weighted minimum cost path\nindices_ecd_costs, weight_ecd = route_through_array(costs_ecd, start, end, fully_connected=True, geometric=True)\nindices_ecd_costs = np.stack(indices_ecd_costs, axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.150445Z","iopub.status.idle":"2025-01-05T18:27:13.150795Z","shell.execute_reply.started":"2025-01-05T18:27:13.150629Z","shell.execute_reply":"2025-01-05T18:27:13.150647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot optimal route\nplt.figure(figsize=(10,17))\n\n# Costs\nplt.imshow(costs[0], aspect='auto')\nplt.title(\"RF: Speed costs day one\", fontsize = 16, pad = 18)\n# plt.axis('off')\nplt.gca().invert_yaxis()\n\nplt.figure(figsize=(10,17))\nplt.imshow(costs[1], aspect='auto')\nplt.title(\"RF: Speed costs day two\", fontsize = 16, pad = 18)\nplt.gca().invert_yaxis()\n\nplt.figure(figsize=(10,17))\nplt.imshow(costs[2], aspect='auto')\nplt.title(\"RF: Speed costs day three\", fontsize = 16, pad = 18)\nplt.gca().invert_yaxis()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.151858Z","iopub.status.idle":"2025-01-05T18:27:13.152243Z","shell.execute_reply.started":"2025-01-05T18:27:13.152075Z","shell.execute_reply":"2025-01-05T18:27:13.152093Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot optimal routes with minimum cost path\nplt.figure(figsize=(10,17))\n\n# Costs\nplt.imshow(costs_ecd, aspect='auto')\n\nplt.plot(rf_indices[1], rf_indices[0], 'grey', label = 'One day (Simple solution)')\nplt.plot(merged_indices_all_times[1], merged_indices_all_times[0], 'cyan', label = 'Three days (mean)')\nplt.plot(indices_ecd_costs[1],indices_ecd_costs[0], 'red', label = 'Three days (separated)', lw = 5)\n\n# Start/end points\nplt.plot(start_lon, start_lat, 'k^', markersize = 15, color = 'white')\nplt.text(start_lon - 70, start_lat - 10, 'Lisbon', fontsize = 20, color = 'white')\nplt.plot(end_lon, end_lat, 'k*', markersize = 15)\nplt.text(end_lon + 30, end_lat - 3, 'Rio de Janeiro', fontsize = 20)\n# plt.title('Advanced solution (split)', fontsize = 18, pad = 12)\nplt.legend(loc = 'lower right', prop={'size': 20})\n#plt.colorbar(label = 'Inverted speed over ground')\nplt.axis('off')\nplt.gca().invert_yaxis()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.153587Z","iopub.status.idle":"2025-01-05T18:27:13.154025Z","shell.execute_reply.started":"2025-01-05T18:27:13.153764Z","shell.execute_reply":"2025-01-05T18:27:13.153787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot and compare fastest routes\nfig, (ax2, ax1) = plt.subplots(1, 2, figsize=(20,17))\n\n# Costs\nax1.imshow(costs_ecd, aspect='auto')\n\nax1.plot(rf_indices[1], rf_indices[0], 'black', label = 'One day (Simple solution)')\nax1.plot(merged_indices_all_times[1], merged_indices_all_times[0], 'cyan', label = 'Three days (mean)')\nax1.plot(indices_ecd_costs[1],indices_ecd_costs[0], 'red', label = 'Three days (separated)', lw = 5)\n\n\n# Costs\nax2.imshow(day_all_mask, aspect = 'auto',cmap=\"Blues\")\n\nax2.text(300, 700, 'Day 1', color = 'black', fontfamily = 'serif', fontsize = 26)\nax2.text(200, 400, 'Day 2', color = 'black', fontfamily = 'serif', fontsize = 26)\nax2.text(100, 100, 'Day 3', color = 'white', fontfamily = 'serif', fontsize = 26)\n\n# ax1.set_title('Route comparison', fontsize = 18, pad = 12)\n# ax2.set_title('Areas for cost separation', fontsize = 18, pad = 12)\nax1.legend(loc = 'lower right', prop={'size': 16})\n\nax1.axis('off')\nax2.axis('off')\nax1.invert_yaxis()\nax2.invert_yaxis()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.155510Z","iopub.status.idle":"2025-01-05T18:27:13.155920Z","shell.execute_reply.started":"2025-01-05T18:27:13.155694Z","shell.execute_reply":"2025-01-05T18:27:13.155718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute total costs\n# relative to each other; weight_day_one = 1\nprint(\"\\nTotal costs compared to Simple Solution: \")\n# Just one day (day 1)\nprint(\"One day Simple solution: \", weight_simple_day_one/weight_simple_day_one)\n# Mean of all days\nprint(\"All days mean: \", weight_all_times/weight_simple_day_one)\n# Multiple days \nprint(\"All days splitted: \", weight_ecd/weight_simple_day_one)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T18:27:13.157205Z","iopub.status.idle":"2025-01-05T18:27:13.157552Z","shell.execute_reply.started":"2025-01-05T18:27:13.157391Z","shell.execute_reply":"2025-01-05T18:27:13.157408Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cost comparison relative to one day solution\n| One day (RF)| All days mean (RF)| All days splitted (RF)|\n| ----------- | ----------- | ----------- |\n| 1 | 1.06 | 0.95 |\n\n\n-> 5% faster splitting the route costs instead of using just one day","metadata":{}},{"cell_type":"markdown","source":"### References\n* https://levelup.gitconnected.com/dijkstras-shortest-path-algorithm-in-a-grid-eb505eb3a290","metadata":{}}]}